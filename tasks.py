# tasks.py
from datetime import datetime, timedelta
import asyncio
import logging
from main import bot
from discord.ext import tasks, commands
import discord
from io import BytesIO
from typing import Optional, Dict, List
from utils import generate_activity_graph
from collections import defaultdict
import time
import pytz
import json
import os

logger = logging.getLogger('inactivity_bot')

def handle_exception(loop, context):
    """Captura exce√ß√µes n√£o tratadas."""
    logger.error(f"Exce√ß√£o n√£o tratada: {context['message']}", exc_info=context.get('exception'))
    
    # Tenta logar a exce√ß√£o no canal de logs do Discord
    # Usar create_task para n√£o bloquear o handler
    asyncio.create_task(bot.log_action(
        "Exce√ß√£o N√£o Tratada",
        None,
        f"Exce√ß√£o: {context.get('exception')}\nMensagem: {context['message']}"
    ))

class PerformanceMetrics:
    def __init__(self):
        self.db_query_times = []
        self.api_call_times = []
        self.task_execution_times = []  # Adicionando para rastrear tempos de execu√ß√£o de tasks
        self.last_flush = time.time()
    
    def record_db_query(self, duration):
        self.db_query_times.append(duration)
        self._maybe_flush()
    
    def record_api_call(self, duration):
        self.api_call_times.append(duration)
        self._maybe_flush()
    
    def record_task_execution(self, task_name, duration):
        """Registra o tempo de execu√ß√£o de uma task"""
        self.task_execution_times.append((task_name, duration))
        self._maybe_flush()
    
    def _maybe_flush(self):
        if time.time() - self.last_flush > 300:  # 5 minutes
            self._flush_metrics()
            self.last_flush = time.time()
    
    def _flush_metrics(self):
        if self.db_query_times:
            avg_db = sum(self.db_query_times) / len(self.db_query_times)
            max_db = max(self.db_query_times)
            logger.info(f"M√©tricas DB: Avg={avg_db:.3f}s, Max={max_db:.3f}s, Samples={len(self.db_query_times)}")
            self.db_query_times = []
        
        if self.api_call_times:
            avg_api = sum(self.api_call_times) / len(self.api_call_times)
            max_api = max(self.api_call_times)
            logger.info(f"M√©tricas API: Avg={avg_api:.3f}s, Max={max_api:.3f}s, Samples={len(self.api_call_times)}")
            self.api_call_times = []
        
        if self.task_execution_times:
            # Agrupar por nome de task
            task_stats = {}
            for task_name, duration in self.task_execution_times:
                if task_name not in task_stats:
                    task_stats[task_name] = []
                task_stats[task_name].append(duration)
            
            # Logar estat√≠sticas por task
            for task_name, durations in task_stats.items():
                avg = sum(durations) / len(durations)
                max_d = max(durations)
                logger.info(f"M√©tricas Task {task_name}: Avg={avg:.3f}s, Max={max_d:.3f}s, Samples={len(durations)}")
            
            self.task_execution_times = []

# Global instance
perf_metrics = PerformanceMetrics()

class TaskMetrics:
    """Class to track and report task performance metrics"""
    def __init__(self):
        self.execution_times = defaultdict(list)
        self.error_counts = defaultdict(int)
        self.success_counts = defaultdict(int)
    
    def record_execution(self, task_name: str, duration: float):
        self.execution_times[task_name].append(duration)
        # Keep only the last 100 executions for each task
        if len(self.execution_times[task_name]) > 100:
            self.execution_times[task_name].pop(0)
    
    def record_error(self, task_name: str):
        self.error_counts[task_name] += 1
    
    def record_success(self, task_name: str):
        self.success_counts[task_name] += 1
    
    def get_metrics(self, task_name: str) -> Dict:
        times = self.execution_times.get(task_name, [])
        return {
            'last_24h_errors': self.error_counts.get(task_name, 0),
            'last_24h_successes': self.success_counts.get(task_name, 0),
            'avg_time': sum(times)/len(times) if times else 0,
            'min_time': min(times) if times else 0,
            'max_time': max(times) if times else 0,
            'last_10_avg': sum(times[-10:])/len(times[-10:]) if len(times) >= 10 else 0
        }

# Initialize task metrics
task_metrics = TaskMetrics()

def log_task_metrics(task_name: str):
    """Decorator to log task execution metrics"""
    def decorator(func):
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = await func(*args, **kwargs)
                duration = time.time() - start_time
                perf_metrics.record_task_execution(task_name, duration)
                task_metrics.record_success(task_name)
                return result
            except Exception as e:
                duration = time.time() - start_time
                perf_metrics.record_task_execution(task_name, duration)
                task_metrics.record_error(task_name)
                logger.error(f"Error in {task_name}: {e}", exc_info=True)
                raise
        return wrapper
    return decorator

class DynamicBatcher:
    def __init__(self):
        self.batch_size = 10  # Valor inicial
        self.min_batch = 5    # M√≠nimo seguro
        self.max_batch = 50   # M√°ximo permitido
        self.last_rate_limit = None

    async def adjust_batch_size(self):
        """Ajusta dinamicamente o tamanho do lote."""
        now = time.time()

        # Se houve rate limit recentemente, reduz o batch
        if self.last_rate_limit and (now - self.last_rate_limit) < 60:
            self.batch_size = max(self.min_batch, self.batch_size - 5)
        else:
            # Sen√£o, aumenta gradualmente
            self.batch_size = min(self.max_batch, self.batch_size + 2)

    async def handle_rate_limit(self):
        """Chamado quando um rate limit √© detectado."""
        self.last_rate_limit = time.time()
        await self.adjust_batch_size()

class BatchProcessor:
    def __init__(self, bot):
        self.bot = bot
        self.batcher = DynamicBatcher()
        self.max_concurrent = 5  # Limite de opera√ß√µes concorrentes

    async def process_inactivity_batch(self, members: list[discord.Member]):
        """Processa um lote de membros de uma vez com limite concorrente."""
        if not members:
            return []
            
        # Usar sem√°foro para limitar concorr√™ncia
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        async def process_member(member):
            async with semaphore:
                return await self._process_member_optimized(member)
        
        # Processar em lotes menores
        batch_size = min(self.batcher.batch_size, 10)
        results = []
        
        for i in range(0, len(members), batch_size):
            batch = members[i:i + batch_size]
            batch_results = await asyncio.gather(
                *(process_member(member) for member in batch),
                return_exceptions=True
            )
            results.extend(batch_results)
            await asyncio.sleep(self.bot.rate_limit_delay)  # Delay entre lotes
            
        return results

    async def _process_member_optimized(self, member):
        """
        Verifica a inatividade de um membro, processando todos os per√≠odos de monitoramento
        que passaram desde a √∫ltima verifica√ß√£o e envia avisos para o per√≠odo atual.
        """
        result = {'processed': 0, 'removed': 0, 'warnings': {'first': 0, 'second': 0}}
        try:
            # 1. Verificar se o membro deve ser processado
            if member.bot or member.id in self.bot.config['whitelist']['users'] or \
                any(role.id in self.bot.config['whitelist']['roles'] for role in member.roles):
                return result

            tracked_roles_ids = self.bot.config.get('tracked_roles', [])
            current_member_roles = [role for role in member.roles if role.id in tracked_roles_ids]
            if not current_member_roles:
                return result # Membro n√£o possui mais os cargos monitorados

            result['processed'] = 1
            now = datetime.now(pytz.UTC)
            monitoring_period_days = self.bot.config.get('monitoring_period')
            period_duration = timedelta(days=monitoring_period_days)
            anchor_date = None

            # 2. Determinar a data √¢ncora (in√≠cio da contagem)
            # A prioridade √© a data de atribui√ß√£o mais recente de um cargo monitorado
            assigned_times = await asyncio.gather(
                *[self.bot.db.get_role_assigned_time(member.id, member.guild.id, role.id)
                    for role in current_member_roles],
                return_exceptions=True
            )
            valid_times = [t for t in assigned_times if isinstance(t, datetime)]
            if valid_times:
                anchor_date = max(valid_times)
                if anchor_date.tzinfo is None: anchor_date = anchor_date.replace(tzinfo=pytz.UTC)

            # Se n√£o h√° data de atribui√ß√£o, usar a √∫ltima verifica√ß√£o
            if not anchor_date:
                last_check = await self.bot.db.get_last_period_check(member.id, member.guild.id)
                if last_check:
                    anchor_date = last_check['period_start']
                    if anchor_date.tzinfo is None: anchor_date = anchor_date.replace(tzinfo=pytz.UTC)

            # Se n√£o h√° √¢ncora, n√£o podemos processar
            if not anchor_date:
                # Registrar um per√≠odo inicial para que o membro seja verificado no futuro
                initial_start = now - period_duration
                await self.bot.db.log_period_check(member.id, member.guild.id, initial_start, now, False)
                logger.info(f"Nenhuma √¢ncora encontrada para {member.display_name}. Definindo per√≠odo inicial.")
                return result
            
            # 3. Processar todos os per√≠odos CONCLU√çDOS desde a √¢ncora
            current_period_start = anchor_date
            while (current_period_start + period_duration) <= now:
                period_end = current_period_start + period_duration

                # Verificar se este per√≠odo j√° foi avaliado como "cumprido"
                last_check = await self.bot.db.get_last_period_check(member.id, member.guild.id)
                if last_check and last_check['period_start'] == current_period_start and last_check['meets_requirements']:
                    current_period_start += period_duration # Pula para o pr√≥ximo per√≠odo
                    continue

                sessions = await self.bot.db.get_voice_sessions(member.id, member.guild.id, current_period_start, period_end)
                required_minutes = self.bot.config['required_minutes']
                required_days = self.bot.config['required_days']

                valid_days = set()
                for session in sessions:
                    if session['duration'] >= required_minutes * 60:
                        valid_days.add(session['join_time'].date())
                
                meets_requirements = len(valid_days) >= required_days
                await self.bot.db.log_period_check(member.id, member.guild.id, current_period_start, period_end, meets_requirements)

                if not meets_requirements:
                    try:
                        await member.remove_roles(*current_member_roles, reason=f"Inatividade no per√≠odo {current_period_start.date()} a {period_end.date()}")
                        result['removed'] = 1
                        await self.bot.send_warning(member, 'final')
                        await self.bot.db.log_removed_roles(member.id, member.guild.id, [r.id for r in current_member_roles])
                        
                        # Log e notifica√ß√£o para admin (exemplo)
                        log_message = (
                            f"Cargos removidos: {', '.join([r.name for r in current_member_roles])}\n"
                            f"Dias v√°lidos: {len(valid_days)}/{required_days}\n"
                            f"Per√≠odo: {current_period_start.strftime('%d/%m/%Y')} a {period_end.strftime('%d/%m/%Y')}"
                        )
                        await self.bot.log_action("Cargo Removido", member, log_message)
                        
                        return result # Membro perdeu os cargos, encerra o processamento para ele
                    except Exception as e:
                        logger.error(f"Erro ao remover cargos de {member.display_name}: {e}")
                        return result # Para de processar para evitar loops de erro

                current_period_start += period_duration # Avan√ßa para o pr√≥ximo per√≠odo

            # 4. Checar o per√≠odo ATUAL para enviar avisos
            final_period_start = current_period_start
            final_period_end = final_period_start + period_duration
            days_remaining = (final_period_end - now).days

            warnings_config = self.bot.config.get('warnings', {})
            first_warning_days = warnings_config.get('first_warning', 7)
            second_warning_days = warnings_config.get('second_warning', 1)

            
# --- Checar se o PER√çODO ATUAL j√° cumpre os requisitos antes de enviar avisos ---
try:
    sessions_now = await self.bot.db.get_voice_sessions(
        member.id, member.guild.id, final_period_start, now
    )
    required_minutes = self.bot.config.get('required_minutes', 60)
    required_days = self.bot.config.get('required_days', 5)

    # agregar por dia
    daily_totals_now = {}
    if sessions_now:
        for s in sessions_now:
            if s.get('duration', 0) > 0:
                join_dt = s.get('join_time')
                if join_dt is not None:
                    daily_totals_now[join_dt.date()] = daily_totals_now.get(join_dt.date(), 0) + s.get('duration', 0)

    valid_days_current = sum(1 for total in daily_totals_now.values() if total >= (required_minutes * 60))

    if valid_days_current >= required_days:
        logger.debug(
            f"{member.display_name} j√° cumpre requisitos no per√≠odo atual ({valid_days_current}/{required_days} dias) ‚Äî pulando avisos."
        )
    else:
        warnings_in_period = await self.bot.db.get_warnings_in_period(
            member.id, member.guild.id, final_period_start
        ) or []

        if days_remaining <= first_warning_days and 'first' not in warnings_in_period:
            await self.bot.send_warning(member, 'first')
            result['warnings']['first'] += 1
            logger.info(f"Primeiro aviso enviado para {member.display_name}. Days remaining: {days_remaining}")
        elif days_remaining <= second_warning_days and 'second' not in warnings_in_period:
            await self.bot.send_warning(member, 'second')
            result['warnings']['second'] += 1
            logger.info(f"Segundo aviso enviado para {member.display_name}. Days remaining: {days_remaining}")
except Exception as e:
    logger.error(f"Erro ao avaliar/decidir avisos para {member.display_name}: {e}", exc_info=True)

            result['warnings']['first'] += 1
            elif days_remaining <= second_warning_days and 'second' not in warnings_in_period:
                await self.bot.send_warning(member, 'second')
            result['warnings']['second'] += 1

        except Exception as e:
            logger.error(f"Erro ao verificar inatividade para {member.display_name}: {e}", exc_info=True)

     return result

def prioritize_members(members: list[discord.Member]) -> list[discord.Member]:
    """Ordena membros para processar os mais prov√°veis de estarem inativos primeiro."""
    return sorted(
        members,
        key=lambda m: (
            m.joined_at.timestamp() if m.joined_at else 0,  # Mais antigos primeiro
            len(m.roles),  # Membros com menos cargos primeiro
        ),
        reverse=False
    )

async def voice_event_processor():
    """Processa eventos de voz da fila principal"""
    await bot.wait_until_ready()
    while True:
        try:
            event = await bot.voice_event_queue.get()
            await bot._process_voice_batch([event])
            bot.voice_event_queue.task_done()
            await asyncio.sleep(0.1)
        except Exception as e:
            logger.error(f"Erro no processador de eventos de voz: {e}")
            await asyncio.sleep(1)

async def execute_task_with_persistent_interval(task_name: str, monitoring_period: int, task_func: callable, force_check: bool = False):
    """Executa a task mantendo intervalo persistente de 24h, de forma mais robusta."""
    await bot.wait_until_ready()
    
    # Esperar at√© que o banco de dados esteja inicializado
    while not hasattr(bot, 'db') or not bot.db or not bot.db._is_initialized:
        await asyncio.sleep(5)
        logger.info(f"Aguardando inicializa√ß√£o do banco de dados para a task {task_name}...")
    
    while True:
        try:
            # Verificar √∫ltima execu√ß√£o
            last_exec = None
            if hasattr(bot.db, 'get_last_task_execution'):
                try:
                    last_exec = await bot.db.get_last_task_execution(task_name)
                except AttributeError:
                    logger.warning(f"M√©todo get_last_task_execution n√£o dispon√≠vel no banco de dados")
            
            now = datetime.now(pytz.UTC)
            should_execute = False

            if force_check:
                should_execute = True
                logger.info(f"Execu√ß√£o for√ßada para a task {task_name}")
            elif not last_exec:  # Primeira execu√ß√£o
                should_execute = True
                logger.info(f"Primeira execu√ß√£o da task {task_name}")
            else:
                # Garantir que last_exec_time est√° com timezone (aware)
                last_exec_time = last_exec['last_execution']
                if last_exec_time.tzinfo is None:
                    last_exec_time = last_exec_time.replace(tzinfo=pytz.UTC)
                
                # *** IN√çCIO DA L√ìGICA CORRIGIDA ***
                next_scheduled_run = last_exec_time + timedelta(hours=24)
                
                if now >= next_scheduled_run:
                    should_execute = True
                    logger.info(f"Pr√≥xima execu√ß√£o agendada ({next_scheduled_run.strftime('%Y-%m-%d %H:%M')}) foi atingida. Executando task {task_name}")
                else:
                    # Log para informar por que a task n√£o est√° rodando
                    remaining_time = next_scheduled_run - now
                    logger.info(f"Task '{task_name}' n√£o precisa ser executada ainda. Pr√≥xima execu√ß√£o em: {str(remaining_time).split('.')[0]}")
                # *** FIM DA L√ìGICA CORRIGIDA ***

            if should_execute:
                logger.info(f"Executando task {task_name}...")
                start_time = time.time()
                await task_func()
                perf_metrics.record_task_execution(task_name, time.time() - start_time)

                # Registrar a execu√ß√£o com o tempo atual
                if hasattr(bot.db, 'log_task_execution'):
                    try:
                        period_to_log = monitoring_period
                        if task_name in ['inactivity_check', 'cleanup_members']:
                            period_to_log = bot.config.get('monitoring_period', monitoring_period)
                        
                        await bot.db.log_task_execution(task_name, period_to_log)
                    except AttributeError:
                        logger.warning(f"M√©todo log_task_execution n√£o dispon√≠vel no banco de dados")
                
                logger.info(f"Task {task_name} conclu√≠da com sucesso")
            
            # Esperar 1h antes de verificar novamente (evita loops muito r√°pidos)
            await asyncio.sleep(3600)
                
        except Exception as e:
            logger.error(f"Erro na task {task_name}: {e}", exc_info=True)
            await asyncio.sleep(3600)  # Esperar 1h antes de tentar novamente

async def execute_task_with_retry(task_name: str, task_func: callable, max_retries: int = 3):
    """Executa uma task com tentativas de recupera√ß√£o."""
    retries = 0
    while retries < max_retries:
        try:
            await task_func()
            break
        except Exception as e:
            retries += 1
            logger.error(f"Falha na task {task_name} (tentativa {retries}/{max_retries}): {e}")
            if retries >= max_retries:
                logger.error(f"Task {task_name} falhou ap√≥s {max_retries} tentativas.")
                await bot.log_action(
                    "Falha na Task",
                    None,
                    f"Task {task_name} falhou ap√≥s {max_retries} tentativas: {e}"
                )
            await asyncio.sleep(60 * retries)  # Espera exponencial

@bot.event
async def on_shutdown():
    """Executa a√ß√µes de limpeza antes do desligamento do bot."""
    logger.info("Bot est√° sendo desligado - executando limpeza...")
    await bot.log_action("Desligamento", None, "Bot est√° sendo desligado")
    await save_task_states()
    await emergency_backup()

@bot.event
async def on_resumed():
    """Executa a√ß√µes quando o bot reconecta ap√≥s uma queda."""
    logger.info("Bot reconectado ap√≥s queda")
    
    # Verificar membros em canais de voz imediatamente
    await check_current_voice_members()
    await detect_missing_voice_leaves()  # Limpar sess√µes fantasma
    
    # Limpar filas e reinicializar contadores
    await bot.clear_queues()
    
    await bot.log_action("Reconex√£o", None, "Bot reconectado ap√≥s queda - Filas reinicializadas")
    await process_pending_voice_events()

@bot.event
async def on_disconnect():
    """Executa a√ß√µes quando o bot √© desconectado."""
    logger.warning("Bot desconectado - realizando backup emergencial...")

    # Log members in voice channels
    try:
        active_voice_members = []
        for guild in bot.guilds:
            for member in guild.members:
                if member.voice and member.voice.channel:
                    active_voice_members.append(f"{member.display_name} in {member.voice.channel.name}")
        if active_voice_members:
            logger.info(f"Membros em canais de voz no momento da desconex√£o: {', '.join(active_voice_members)}")
        else:
            logger.info("Nenhum membro em canais de voz no momento da desconex√£o.")
    except Exception as e:
        logger.error(f"Erro ao registrar membros em voz na desconex√£o: {e}")

    await emergency_backup()

async def save_task_states():
    """Salva o estado atual das tasks no banco de dados."""
    try:
        # Verificar se o banco de dados est√° dispon√≠vel
        if not hasattr(bot, 'db') or not bot.db or not bot.db._is_initialized:
            logger.error("Banco de dados n√£o inicializado - pulando salvamento de estados")
            return

        for task_name in ['inactivity_check', 'cleanup_members']:
            last_exec = await bot.db.get_last_task_execution(task_name)
            if last_exec:
                await bot.db.log_task_execution(task_name, last_exec['monitoring_period'])
        logger.info("Estados das tasks salvos com sucesso.")
    except Exception as e:
        logger.error(f"Erro ao salvar estados das tasks: {e}")

async def load_task_states():
    """Carrega o estado das tasks do banco de dados."""
    try:
        # Verificar se o banco de dados est√° dispon√≠vel
        if not hasattr(bot, 'db') or not bot.db or not bot.db._is_initialized:
            logger.error("Banco de dados n√£o inicializado - pulando carregamento de estados")
            return

        for task_name in ['inactivity_check', 'cleanup_members']:
            last_exec = await bot.db.get_last_task_execution(task_name)
            if last_exec:
                await bot.db.log_task_execution(task_name, last_exec['monitoring_period'])
        logger.info("Estados das tasks carregados com sucesso.")
    except Exception as e:
        logger.error(f"Erro ao carregar estados das tasks: {e}")

def serialize_sessions(sessions):
    """Converte o dicion√°rio de sess√µes ativas para um formato serializ√°vel."""
    serializable_sessions = {}
    for key, value in sessions.items():
        session_copy = value.copy()
        # Adicionado 'paused_time' √† lista para garantir sua convers√£o para string
        for time_key in ['start_time', 'last_audio_time', 'max_estimated_time', 'audio_off_time', 'paused_time']:
            if time_key in session_copy and isinstance(session_copy[time_key], datetime):
                # Converter datetime para string ISO formatada
                session_copy[time_key] = session_copy[time_key].isoformat()
        serializable_sessions[str(key)] = session_copy
    return serializable_sessions

async def emergency_backup():
    """Realiza um backup emergencial dos dados cr√≠ticos."""
    try:
        logger.info("Iniciando backup emergencial...")
        # Backup do estado das sess√µes ativas
        try:
            sessions_backup_path = os.path.join('backups', 'active_sessions_backup.json')
            with open(sessions_backup_path, 'w', encoding='utf-8') as f:
                json.dump(serialize_sessions(bot.active_sessions), f, indent=4)
            logger.info(f"Backup das sess√µes ativas salvo em {sessions_backup_path}")
        except Exception as e:
            logger.error(f"Falha ao salvar backup das sess√µes ativas: {e}")

        if not hasattr(bot, 'db_backup') or bot.db_backup is None:
            try:
                if not hasattr(bot, 'db') or not bot.db:
                    logger.error("Banco de dados n√£o dispon√≠vel para backup")
                    return False
                    
                from database import DatabaseBackup
                bot.db_backup = DatabaseBackup(bot.db)
                await asyncio.sleep(1)  # Garante inicializa√ß√£o
            except Exception as e:
                logger.error(f"Erro ao criar inst√¢ncia de DatabaseBackup: {e}")
                return False
        
        try:
            if hasattr(bot.db_backup, 'create_backup'):
                start_time = time.time()
                success = await bot.db_backup.create_backup()
                perf_metrics.record_db_query(time.time() - start_time)
                
                if success:
                    logger.info("Backup emergencial conclu√≠do com sucesso.")
                    return True
                else:
                    logger.error("Backup emergencial falhou.")
                    return False
            else:
                logger.error("M√©todo create_backup n√£o dispon√≠vel no DatabaseBackup")
                return False
        except Exception as e:
            logger.error(f"Falha no backup emergencial: {e}")
            return False
    except Exception as e:
        logger.error(f"Erro inesperado durante backup emergencial: {e}")
        return False

async def health_check():
    """Wrapper para a task com intervalo persistente"""
    await execute_task_with_persistent_interval(
        "health_check",
        1,  # Verifica a cada hora
        _health_check
    )

async def _health_check():
    """Verifica a sa√∫de do bot e reinicia tasks se necess√°rio."""
    await bot.wait_until_ready()
    
    if not hasattr(bot, 'db') or not bot.db or not bot.db._is_initialized:
        logger.error("Banco de dados n√£o inicializado - pulando verifica√ß√£o de sa√∫de")
        return

    try:
        # Verificar √∫ltima execu√ß√£o das tasks cr√≠ticas
        critical_tasks = ['inactivity_check', 'cleanup_members']
        for task_name in critical_tasks:
            last_exec = await bot.db.get_last_task_execution(task_name)
            if last_exec:
                last_exec_time = last_exec['last_execution']
                if last_exec_time.tzinfo is None:
                    last_exec_time = last_exec_time.replace(tzinfo=pytz.UTC)
                
                time_since_last = datetime.now(pytz.UTC) - last_exec_time
                if time_since_last > timedelta(hours=26):  # 2 horas de toler√¢ncia
                    # CORRE√á√ÉO: N√≠vel do log alterado de WARNING para INFO
                    logger.info(f"Task {task_name} n√£o executou nos √∫ltimos {time_since_last}")
                    await bot.log_action(
                        "Alerta de Task",
                        None,
                        f"Task {task_name} n√£o executou nos √∫ltimos {time_since_last}"
                    )
        
        # Obter todas as tasks ativas por nome
        active_tasks = {t.get_name() for t in asyncio.all_tasks() if t.get_name()}
        
        expected_tasks = {
            'inactivity_check_wrapper',
            'cleanup_members_wrapper',
            'database_backup_wrapper',
            'cleanup_old_data_wrapper',
            'monitor_rate_limits_wrapper',
            'report_metrics_wrapper',
            'health_check_wrapper',
            'queue_processor',
            'db_pool_monitor',
            'periodic_health_check',
            'audio_state_checker',
            'process_pending_voice_events',
            'check_current_voice_members',
            'detect_missing_voice_leaves',
            'cleanup_ghost_sessions_wrapper',
            'register_role_assignments_wrapper'
        }

        for task_name in expected_tasks:
            if task_name not in active_tasks:
                logger.warning(f"Task {task_name} n√£o est√° ativa - reiniciando...")
                if task_name == 'inactivity_check_wrapper':
                    asyncio.create_task(inactivity_check(), name='inactivity_check_wrapper')
                elif task_name == 'cleanup_members_wrapper':
                    asyncio.create_task(cleanup_members(), name='cleanup_members_wrapper')
                elif task_name == 'database_backup_wrapper':
                    asyncio.create_task(database_backup(), name='database_backup_wrapper')
                elif task_name == 'cleanup_old_data_wrapper':
                    asyncio.create_task(cleanup_old_data(), name='cleanup_old_data_wrapper')
                elif task_name == 'monitor_rate_limits_wrapper':
                    asyncio.create_task(monitor_rate_limits(), name='monitor_rate_limits_wrapper')
                elif task_name == 'report_metrics_wrapper':
                    asyncio.create_task(report_metrics(), name='report_metrics_wrapper')
                elif task_name == 'health_check_wrapper':
                    asyncio.create_task(health_check(), name='health_check_wrapper')
                elif task_name == 'queue_processor':
                    asyncio.create_task(bot.process_queues(), name='queue_processor')
                elif task_name == 'db_pool_monitor':
                    asyncio.create_task(bot.monitor_db_pool(), name='db_pool_monitor')
                elif task_name == 'periodic_health_check':
                    asyncio.create_task(bot.periodic_health_check(), name='periodic_health_check')
                elif task_name == 'audio_state_checker':
                    asyncio.create_task(bot.check_audio_states(), name='audio_state_checker')
                elif task_name == 'process_pending_voice_events':
                    asyncio.create_task(process_pending_voice_events(), name='process_pending_voice_events')
                elif task_name == 'check_current_voice_members':
                    asyncio.create_task(check_current_voice_members(), name='check_current_voice_members')
                elif task_name == 'detect_missing_voice_leaves':
                    asyncio.create_task(detect_missing_voice_leaves(), name='detect_missing_voice_leaves')
                elif task_name == 'cleanup_ghost_sessions_wrapper':
                    asyncio.create_task(cleanup_ghost_sessions(), name='cleanup_ghost_sessions_wrapper')
                elif task_name == 'register_role_assignments_wrapper':
                    asyncio.create_task(register_role_assignments(), name='register_role_assignments_wrapper')

        await bot.log_action("Verifica√ß√£o de Sa√∫de", None, f"Tasks ativas: {', '.join(t for t in active_tasks if t)}")
    except Exception as e:
        logger.error(f"Erro na verifica√ß√£o de sa√∫de: {e}")

@log_task_metrics("inactivity_check")
async def _inactivity_check():
    """Verifica a inatividade dos membros, envia avisos e remove cargos se necess√°rio"""
    await bot.wait_until_ready()
    
    # Verificar configura√ß√£o essencial
    if 'tracked_roles' not in bot.config or not bot.config['tracked_roles']:
        logger.info("Nenhum cargo monitorado definido - verifica√ß√£o de inatividade ignorada")
        return
    
    # Verificar se o banco de dados est√° dispon√≠vel
    if not hasattr(bot, 'db') or not bot.db or not bot.db._is_initialized:
        logger.error("Banco de dados n√£o inicializado - pulando verifica√ß√£o de inatividade")
        return
    
    # Log de depura√ß√£o para configura√ß√µes
    logger.debug(f"Configura√ß√£o atual: {bot.config}")
    logger.debug(f"Monitoring period: {bot.config.get('monitoring_period')}")
    
    tracked_roles_ids = set(bot.config['tracked_roles'])
    
    if not tracked_roles_ids:
        logger.info("Nenhum cargo monitorado definido - verifica√ß√£o de inatividade ignorada")
        return
    
    processed_members = 0
    members_with_roles_removed = 0
    warnings_sent = {'first': 0, 'second': 0}
    
    for guild in bot.guilds:
        try:
            # Em vez de depender de `role.members` (que usa o cache), iteramos por
            # todos os membros do servidor e verificamos se eles possuem algum dos cargos monitorados.
            # Isso √© mais confi√°vel, especialmente com o `members intent` ativado.
            members_to_check = [
                member for member in guild.members
                if not member.bot and any(role.id in tracked_roles_ids for role in member.roles)
            ]

            # Priorizar membros para processamento
            prioritized_members = prioritize_members(members_to_check)
            processor = BatchProcessor(bot)
            
            # Processar em lotes otimizados
            results = await processor.process_inactivity_batch(prioritized_members)
            
            # Atualizar contadores
            for res in results:
                if not isinstance(res, Exception) and isinstance(res, dict):
                    processed_members += res.get('processed', 0)
                    members_with_roles_removed += res.get('removed', 0)
                    warnings_sent['first'] += res.get('warnings', {}).get('first', 0)
                    warnings_sent['second'] += res.get('warnings', {}).get('second', 0)
                
        except Exception as e:
            logger.error(f"Erro ao verificar inatividade na guild {guild.name}: {e}")
            continue
    
    logger.info(f"Verifica√ß√£o de inatividade conclu√≠da. Membros processados: {processed_members}, Cargos removidos: {members_with_roles_removed}, Avisos enviados: Primeiro={warnings_sent['first']}, Segundo={warnings_sent['second']}")

async def inactivity_check():
    """Wrapper para a task com intervalo de 24h"""
    monitoring_period = bot.config['monitoring_period']
    task = bot.loop.create_task(
        execute_task_with_persistent_interval(
            "inactivity_check", 
            monitoring_period,
            _inactivity_check
        ), 
        name='inactivity_check_wrapper'
    )
    return task

@log_task_metrics("cleanup_members")
async def _cleanup_members(force_check: bool = False):
    """L√≥gica original da task"""
    await bot.wait_until_ready()
    
    # Verificar se o banco de dados est√° dispon√≠vel
    if not hasattr(bot, 'db') or not bot.db or not bot.db._is_initialized:
        logger.error("Banco de dados n√£o inicializado - pulando limpeza de membros")
        return
    
    # Log de depura√ß√£o para configura√ß√µes
    logger.debug(f"Configura√ß√£o atual: {bot.config}")
    logger.debug(f"Kick after days: {bot.config.get('kick_after_days')}")
    
    kick_after_days = bot.config['kick_after_days']
    if kick_after_days <= 0:
        logger.info("Expuls√£o de membros inativos desativada na configura√ß√£o")
        return
    
    members_kicked = 0
    batch_size = bot._batch_processing_size
    
    for guild in bot.guilds:
        members = prioritize_members(list(guild.members))  # Priorizar membros mais antigos/sem cargos
        for i in range(0, len(members), batch_size):
            batch = members[i:i + batch_size]
            results = await asyncio.gather(*[
                process_member_cleanup(member, guild, kick_after_days) 
                for member in batch
            ])
            
            members_kicked += sum(results)  # Soma os resultados booleanos (True = 1, False = 0)
            
            await asyncio.sleep(bot.rate_limit_delay)
    
    logger.info(f"Limpeza de membros conclu√≠da. Membros expulsos: {members_kicked}")

async def cleanup_members(force_check: bool = False):
    """Wrapper para a task com intervalo persistente"""
    monitoring_period = bot.config['monitoring_period']
    task = bot.loop.create_task(execute_task_with_persistent_interval(
        "cleanup_members", 
        monitoring_period,
        _cleanup_members,
        force_check=force_check
    ), name='cleanup_members_wrapper')
    return task

async def process_member_cleanup(member: discord.Member, guild: discord.Guild, kick_after_days: int) -> bool:
    """
    Verifica se um membro deve ser expulso por estar sem cargos por um per√≠odo configurado.
    A contagem come√ßa na primeira vez que o bot detecta o membro sem cargos.
    Retorna True se o membro foi expulso, False caso contr√°rio.
    """
    try:
        # Pular bots e usu√°rios na whitelist
        if member.bot or member.id in bot.config['whitelist']['users']:
            return False

        # ID especial usado como marcador na tabela 'removed_roles'
        NO_ROLES_MARKER_ROLE_ID = 0

        # --- L√ìGICA PARA MEMBROS QUE POSSUEM CARGOS ---
        if len(member.roles) > 1:
            # O membro tem cargos. Se havia um marcador de "sem cargos" para ele, removemos.
            try:
                # N√£o √© necess√°rio verificar se existe, o DELETE simplesmente n√£o far√° nada se n√£o encontrar.
                await bot.db.pool.execute(
                    "DELETE FROM removed_roles WHERE user_id = $1 AND guild_id = $2 AND role_id = $3",
                    member.id, guild.id, NO_ROLES_MARKER_ROLE_ID
                )
            except Exception as e:
                logger.error(f"Falha ao tentar limpar o marcador 'sem cargos' para {member.display_name}: {e}")
            return False  # O membro tem cargos, ent√£o n√£o fazemos mais nada.

        # --- L√ìGICA PARA MEMBROS SEM CARGOS (exceto @everyone) ---
        
        # Verificar se j√° existe um marcador de "sem cargos" para este membro
        first_seen_record = await bot.db.pool.fetchrow(
            "SELECT removal_date FROM removed_roles WHERE user_id = $1 AND guild_id = $2 AND role_id = $3",
            member.id, guild.id, NO_ROLES_MARKER_ROLE_ID
        )

        if first_seen_record:
            # J√° vimos este membro sem cargos antes. Verificar h√° quanto tempo.
            first_seen_date = first_seen_record['removal_date']
            if first_seen_date.tzinfo is None:
                first_seen_date = first_seen_date.replace(tzinfo=pytz.UTC)
            
            time_without_roles = datetime.now(pytz.UTC) - first_seen_date

            # Se o tempo sem cargos atingiu o limite configurado, iniciar o processo de expuls√£o.
            if time_without_roles >= timedelta(days=kick_after_days):
                try:
                    # Verificar se o bot tem permiss√£o para expulsar
                    if not guild.me.guild_permissions.kick_members:
                        await bot.log_action("Erro ao Expulsar", member, "O bot n√£o tem permiss√£o para expulsar membros.")
                        return False
                        
                    # Verificar hierarquia de cargos
                    if guild.me.top_role <= member.top_role:
                        await bot.log_action("Erro ao Expulsar", member, "A hierarquia de cargos impede a expuls√£o.")
                        return False

                    await member.kick(reason=f"Sem cargos por mais de {kick_after_days} dias.")
                    
                    # Notificar administradores por DM
                    admin_embed = discord.Embed(
                        title="üë¢ Membro Expulso por Inatividade",
                        description=f"{member.mention} foi expulso do servidor.",
                        color=discord.Color.from_rgb(156, 39, 176),
                        timestamp=datetime.now(pytz.utc)
                    )
                    admin_embed.set_author(name=f"{member.display_name}", icon_url=member.display_avatar.url)
                    admin_embed.add_field(name="Usu√°rio", value=f"{member.mention} (`{member.id}`)", inline=False)
                    admin_embed.add_field(name="Motivo", value=f"Sem cargos por mais de {kick_after_days} dias.", inline=False)
                    admin_embed.set_footer(text=f"Servidor: {guild.name}")
                    await bot.notify_admins_dm(guild, embed=admin_embed)

                    # Registrar a expuls√£o no banco de dados
                    await bot.db.log_kicked_member(member.id, guild.id, f"Sem cargos por mais de {kick_after_days} dias")
                    
                    # Logar a a√ß√£o no canal de logs
                    await bot.log_action("Membro Expulso", member, f"Motivo: Sem cargos por mais de {kick_after_days} dias.\nTempo sem cargos: {time_without_roles.days} dias")
                    await bot.notify_roles(f"üë¢ {member.mention} foi expulso por estar sem cargos h√° mais de {kick_after_days} dias.")
                    
                    # Limpar o marcador ap√≥s a expuls√£o bem-sucedida
                    await bot.db.pool.execute(
                        "DELETE FROM removed_roles WHERE user_id = $1 AND guild_id = $2 AND role_id = $3",
                        member.id, guild.id, NO_ROLES_MARKER_ROLE_ID
                    )
                    
                    return True  # Membro foi expulso
                    
                except discord.Forbidden:
                    await bot.log_action("Erro ao Expulsar", member, "Permiss√µes insuficientes.")
                except discord.HTTPException as e:
                    await bot.log_action("Erro ao Expulsar", member, f"Erro HTTP: {e}")
                except Exception as e:
                    logger.error(f"Erro inesperado ao expulsar membro {member.display_name}: {e}")
                return False
            else:
                # Ainda n√£o atingiu o tempo necess√°rio para expuls√£o, n√£o faz nada.
                return False
        else:
            # √â a primeira vez que vemos este membro sem cargos. Iniciar a contagem.
            try:
                await bot.db.pool.execute(
                    """
                    INSERT INTO removed_roles (user_id, guild_id, role_id, removal_date)
                    VALUES ($1, $2, $3, $4)
                    ON CONFLICT (user_id, guild_id, role_id) DO NOTHING
                    """,
                    member.id, guild.id, NO_ROLES_MARKER_ROLE_ID, datetime.now(pytz.UTC)
                )
                logger.info(f"Iniciando contagem de expuls√£o para {member.display_name} (ID: {member.id}) que est√° sem cargos.")
            except Exception as e:
                logger.error(f"Falha ao inserir marcador 'sem cargos' para {member.display_name}: {e}")
            
            return False # N√£o expulsa na primeira verifica√ß√£o.

    except Exception as e:
        logger.error(f"Erro geral ao processar limpeza para o membro {member.display_name}: {e}", exc_info=True)
        return False


@log_task_metrics("database_backup")
async def _database_backup():
    """L√≥gica original da task"""
    await bot.wait_until_ready()
    
    if not bot.db or not bot.db._is_initialized:
        logger.error("Banco n√£o inicializado - pulando backup")
        return
        
    try:
        if not hasattr(bot, 'db_backup') or bot.db_backup is None:
            from database import DatabaseBackup
            bot.db_backup = DatabaseBackup(bot.db)
            await asyncio.sleep(1)  # Garante inicializa√ß√£o
            
        start_time = time.time()
        success = await bot.db_backup.create_backup()
        perf_metrics.record_db_query(time.time() - start_time)
        
        if success:
            await bot.log_action("Backup do Banco de Dados", None, "Backup di√°rio realizado com sucesso")
            logger.info("Backup do banco de dados conclu√≠do com sucesso")
        else:
            logger.error("Falha ao criar backup do banco de dados")
    except Exception as e:
        logger.error(f"Erro ao executar backup do banco de dados: {e}")
        await bot.log_action("Erro no Backup", None, f"Falha ao criar backup: {str(e)}")

async def database_backup():
    """Wrapper para a task com intervalo persistente"""
    monitoring_period = 1  # Backup should run daily regardless of monitoring period
    task = bot.loop.create_task(execute_task_with_persistent_interval(
        "database_backup", 
        monitoring_period,
        _database_backup
    ), name='database_backup_wrapper')
    return task

@log_task_metrics("cleanup_old_data")
async def _cleanup_old_data():
    """L√≥gica original da task"""
    await bot.wait_until_ready()
    
    # Verificar se o banco de dados est√° dispon√≠vel
    if not hasattr(bot, 'db') or not bot.db or not bot.db._is_initialized:
        logger.error("Banco de dados n√£o inicializado - pulando limpeza de dados antigos")
        return
    
    try:
        # Usar UTC para o cutoff_date
        cutoff_date = datetime.now(pytz.UTC) - timedelta(days=60)
        
        # Processar em lotes menores para evitar timeout
        tables_to_clean = [
            ('voice_sessions', 'leave_time'),
            ('user_warnings', 'warning_date'),
            ('removed_roles', 'removal_date'),
            ('kicked_members', 'kick_date'),
            ('rate_limit_logs', 'log_date'),
            ('pending_voice_events', 'event_time'),
            ('role_assignments', 'assigned_at')
        ]
        
        deleted_counts = {}
        
        for table, date_field in tables_to_clean:
            try:
                start_time = time.time()
                # Usar a sintaxe correta do PostgreSQL para DELETE com LIMIT
                if table == 'voice_sessions':
                    result = await bot.db.execute_query(
                        f"DELETE FROM {table} WHERE id IN (SELECT id FROM {table} WHERE {date_field} < $1 ORDER BY id LIMIT 1000)",
                        (cutoff_date,)
                    )
                else:
                    result = await bot.db.execute_query(
                        f"DELETE FROM {table} WHERE {date_field} < $1",
                        (cutoff_date,)
                    )
                perf_metrics.record_db_query(time.time() - start_time)
                deleted_counts[table] = int(result.split()[1])
                logger.info(f"Removidos {deleted_counts[table]} registros de {table}")
            except Exception as e:
                logger.error(f"Erro ao limpar tabela {table}: {e}")
                deleted_counts[table] = 0
        
        log_message = (
            f"Limpeza de dados antigos conclu√≠da: " +
            ", ".join([f"{table}: {count}" for table, count in deleted_counts.items()])
        )
        
        await bot.log_action("Limpeza de Dados", None, log_message)
        return log_message
        
    except Exception as e:
        logger.error(f"Erro ao limpar dados antigos: {e}")
        await bot.log_action(
            "Erro na Limpeza de Dados", 
            None, 
            f"Falha ao limpar dados antigos: {str(e)}"
        )

async def cleanup_old_data():
    """Wrapper para a task com intervalo persistente"""
    monitoring_period = 7  # Limpeza de dados deve rodar semanalmente
    task = bot.loop.create_task(execute_task_with_persistent_interval(
        "cleanup_old_data",
        monitoring_period,
        _cleanup_old_data
    ), name='cleanup_old_data_wrapper')
    return task

@log_task_metrics("monitor_rate_limits")
async def _monitor_rate_limits():
    """L√≥gica original da task"""
    await bot.wait_until_ready()
    
    try:
        # Verificar uso atual
        global_bucket = bot.rate_limit_buckets['global']
        global_usage = 1 - (global_bucket['remaining'] / global_bucket['limit'])
        
        # Ajustar dinamicamente o tamanho dos lotes
        previous_batch_size = bot._batch_processing_size
        
        if global_usage > 0.8:  # Se estiver usando mais de 80% do rate limit
            bot._batch_processing_size = max(5, bot._batch_processing_size - 2)
        elif global_usage < 0.3:  # Se estiver usando menos de 30%
            bot._batch_processing_size = min(20, bot._batch_processing_size + 2)
        
        # S√≥ enviar notifica√ß√£o se houver mudan√ßa significativa ou situa√ß√£o cr√≠tica
        should_notify = False
        notification_message = ""
        
        # Verificar se houve mudan√ßa no tamanho do lote
        if bot._batch_processing_size != previous_batch_size:
            should_notify = True
            notification_message += (
                f"üìä **Ajuste de Rate Limits**\n"
                f"Tamanho do lote alterado de {previous_batch_size} para {bot._batch_processing_size}\n"
            )
        
        # Verificar se est√° pr√≥ximo do limite global
        if global_usage > 0.7:
            should_notify = True
            notification_message += (
                f"‚ö†Ô∏è **Alerta de Uso Elevado**\n"
                f"Uso global: {global_usage*100:.1f}%\n"
                f"Remaining: {global_bucket['remaining']}/{global_bucket['limit']}\n"
                f"Reset em: {max(0, global_bucket['reset_at'] - time.time()):.0f}s\n"
            )
        
        # Enviar notifica√ß√£o se necess√°rio
        if should_notify:
            await bot.log_action(
                "Monitoramento de Rate Limits",
                None,
                notification_message + 
                f"Delay atual: {bot.rate_limit_delay:.2f}s"
            )
            
    except Exception as e:
        logger.error(f"Erro no monitoramento de rate limits: {e}")

async def monitor_rate_limits():
    """Wrapper para a task com intervalo persistente"""
    monitoring_period = 1  # Rate limit monitoring should run frequently regardless of monitoring period
    task = bot.loop.create_task(execute_task_with_persistent_interval(
        "monitor_rate_limits", 
        monitoring_period,
        _monitor_rate_limits
    ), name='monitor_rate_limits_wrapper')
    return task

@log_task_metrics("report_metrics")
async def _report_metrics():
    """L√≥gica original da task"""
    await bot.wait_until_ready()
    
    # Verificar se o banco de dados est√° dispon√≠vel
    if not hasattr(bot, 'db') or not bot.db or not bot.db._is_initialized:
        logger.error("Banco de dados n√£o inicializado - pulando relat√≥rio de m√©tricas")
        return
    
    try:
        metrics_report = []
        for task_name in ['inactivity_check', 'cleanup_members', 
                         'database_backup', 'cleanup_old_data', 'monitor_rate_limits',
                         'cleanup_ghost_sessions', 'register_role_assignments']:
            metrics = task_metrics.get_metrics(task_name)
            metrics_report.append(
                f"**{task_name}**:\n"
                f"- Execu√ß√µes bem-sucedidas: {metrics['last_24h_successes']}\n"
                f"- Erros: {metrics['last_24h_errors']}\n"
                f"- Tempo m√©dio: {metrics['avg_time']:.2f}s\n"
                f"- √öltimas 10 execu√ß√µes: {metrics['last_10_avg']:.2f}s\n"
            )
        
        await bot.log_action(
            "Relat√≥rio de M√©tricas Di√°rias",
            None,
            "\n".join(metrics_report))
        
        # Reset counts for the new day
        task_metrics.error_counts.clear()
        task_metrics.success_counts.clear()
    except Exception as e:
        logger.error(f"Erro ao gerar relat√≥rio de m√©tricas: {e}")

async def report_metrics():
    """Wrapper para a task com intervalo persistente"""
    monitoring_period = 1  # Metrics reporting should run daily regardless of monitoring period
    task = bot.loop.create_task(execute_task_with_persistent_interval(
        "report_metrics", 
        monitoring_period,
        _report_metrics
    ), name='report_metrics_wrapper')
    return task

async def generate_activity_report(member: discord.Member, sessions: list) -> Optional[discord.File]:
    """Gera um relat√≥rio gr√°fico de atividade e retorna como discord.File"""
    if not sessions:
        return None

    try:
        return await generate_activity_graph(member, sessions)
    except Exception as e:
        logger.error(f"Erro ao gerar relat√≥rio gr√°fico: {e}")
        return None

async def _execute_force_check(member: discord.Member):
    """Executa uma verifica√ß√£o for√ßada de inatividade para um membro espec√≠fico"""
    try:
        # Verificar se o banco de dados est√° dispon√≠vel
        if not hasattr(bot, 'db') or not bot.db or not bot.db._is_initialized:
            logger.error("Banco de dados n√£o inicializado - pulando verifica√ß√£o for√ßada")
            return None

        guild = member.guild
        required_minutes = bot.config['required_minutes']
        required_days = bot.config['required_days']
        monitoring_period = bot.config['monitoring_period']
        
        # Definir per√≠odo de verifica√ß√£o em UTC
        period_end = datetime.now(pytz.UTC)
        period_start = period_end - timedelta(days=monitoring_period)
        
        # Obter sess√µes de voz no per√≠odo
        start_time = time.time()
        sessions = await bot.db.get_voice_sessions(member.id, guild.id, period_start, period_end)
        perf_metrics.record_db_query(time.time() - start_time)
        
        # Verificar requisitos
        meets_requirements = False
        valid_days = set()
        
        if sessions:
            for session in sessions:
                if session['duration'] >= required_minutes * 60:
                    day = session['join_time'].date()  # J√° est√° em UTC
                    valid_days.add(day)
            
            meets_requirements = len(valid_days) >= required_days
        
        # Registrar verifica√ß√£o
        start_time = time.time()
        await bot.db.log_period_check(member.id, guild.id, period_start, period_end, meets_requirements)
        perf_metrics.record_db_query(time.time() - start_time)
        
        return {
            'meets_requirements': meets_requirements,
            'valid_days': len(valid_days),
            'required_days': required_days,
            'sessions_count': len(sessions),
            'period_start': period_start,
            'period_end': period_end
        }
        
    except Exception as e:
        logger.error(f"Erro na verifica√ß√£o for√ßada para {member}: {e}")
        raise

async def process_pending_voice_events():
    """Processa eventos de voz pendentes que foram salvos no banco de dados"""
    await bot.wait_until_ready()
    
    if not hasattr(bot, 'db') or not bot.db or not bot.db._is_initialized:
        logger.error("Banco de dados n√£o inicializado - pulando processamento de eventos pendentes")
        return
    
    try:
        # Obter eventos pendentes
        pending_events = await bot.db.get_pending_voice_events(limit=500)
        if not pending_events:
            logger.info("Nenhum evento de voz pendente para processar")
            return
            
        logger.info(f"Processando {len(pending_events)} eventos de voz pendentes...")
        
        # Processar em lotes
        batch_size = 50
        processed_ids = []
        
        for event in pending_events:
            try:
                guild = bot.get_guild(event['guild_id'])
                if not guild:
                    processed_ids.append(event['id'])
                    continue
                    
                member = guild.get_member(event['user_id'])
                if not member:
                    processed_ids.append(event['id'])
                    continue
                
                # Verificar se os canais existem
                before_channel = guild.get_channel(event['before_channel_id']) if event['before_channel_id'] else None
                after_channel = guild.get_channel(event['after_channel_id']) if event['after_channel_id'] else None
                
                # Criar objetos VoiceState
                before_data = {
                    'channel_id': event['before_channel_id'],
                    'self_deaf': event['before_self_deaf'],
                    'deaf': event['before_deaf'],
                    'self_mute': False,
                    'mute': False,
                    'self_stream': False,
                    'self_video': False,
                    'suppress': False,
                    'requested_to_speak_at': None,
                }
                
                after_data = {
                    'channel_id': event['after_channel_id'],
                    'self_deaf': event['after_self_deaf'],
                    'deaf': event['after_deaf'],
                    'self_mute': False,
                    'mute': False,
                    'self_stream': False,
                    'self_video': False,
                    'suppress': False,
                    'requested_to_speak_at': None,
                }
                
                # Enfileirar para processamento
                await bot.voice_event_queue.put((
                    event['event_type'],
                    member,
                    discord.VoiceState(data=before_data, channel=before_channel),
                    discord.VoiceState(data=after_data, channel=after_channel)
                ))
                
                processed_ids.append(event['id'])
                
            except Exception as e:
                logger.error(f"Erro ao processar evento pendente {event['id']}: {e}")
                continue
                
            # Marcar como processados a cada lote
            if len(processed_ids) >= batch_size:
                await bot.db.mark_events_as_processed(processed_ids)
                processed_ids = []
                await asyncio.sleep(1)  # Pequeno delay entre lotes
        
        # Marcar quaisquer eventos restantes como processados
        if processed_ids:
            await bot.db.mark_events_as_processed(processed_ids)
        
        logger.info("Processamento de eventos pendentes conclu√≠do")
        
    except Exception as e:
        logger.error(f"Erro no processamento de eventos pendentes: {e}")

@log_task_metrics("check_current_voice_members")
async def check_current_voice_members():
    """Verifica todos os canais de voz e atualiza o estado interno, incluindo a limpeza de sess√µes fantasma."""
    await bot.wait_until_ready()

    try:
        logger.info("Iniciando verifica√ß√£o de membros em canais de voz...")
        
        # Limpeza de sess√µes fantasma na mem√≥ria
        active_session_keys = list(bot.active_sessions.keys())
        for key in active_session_keys:
            user_id, guild_id = key
            guild = bot.get_guild(guild_id)
            if not guild:
                del bot.active_sessions[key]
                logger.info(f"Removida sess√£o para guild {guild_id} (n√£o encontrada).")
                continue
            
            member = guild.get_member(user_id)
            if not member or not member.voice or not member.voice.channel:
                del bot.active_sessions[key]
                logger.info(f"Removida sess√£o fantasma para {user_id} na guild {guild_id}.")
                continue

        # Verifica√ß√£o de membros atualmente em voz
        for guild in bot.guilds:
            for voice_channel in guild.voice_channels:
                for member in voice_channel.members:
                    if member.bot:
                        continue
                        
                    audio_key = (member.id, guild.id)
                    
                    # Se j√° existe sess√£o ativa, pular
                    if audio_key in bot.active_sessions:
                        continue
                        
                    # Criar sess√£o com tempo m√°ximo de 5 minutos (estimativa conservadora)
                    max_estimated_duration = timedelta(minutes=5)
                    estimated_start = datetime.now(pytz.UTC) - max_estimated_duration
                    
                    # Obter a √∫ltima entrada do banco de dados para evitar discrep√¢ncias
                    try:
                        last_join = await bot.db.get_user_activity(member.id, guild.id)
                        if last_join and last_join.get('last_voice_join'):
                            # Usar o mais recente entre: agora-5min ou √∫ltimo registro no banco
                            estimated_start = min(
                                estimated_start,
                                last_join['last_voice_join']
                            )
                    except Exception as e:
                        logger.error(f"Erro ao obter √∫ltima entrada para {member}: {e}")
                    
                    bot.active_sessions[audio_key] = {
                        'start_time': estimated_start,
                        'last_audio_time': datetime.now(pytz.UTC),
                        'audio_disabled': member.voice.self_deaf or member.voice.deaf,
                        'total_audio_off_time': 0,
                        'estimated': True,
                        'max_estimated_time': datetime.now(pytz.UTC) + max_estimated_duration
                    }
                    
                    logger.info(f"Sess√£o estimada criada para {member.display_name} no canal {voice_channel.name} - In√≠cio: {estimated_start}")
                    
        logger.info("Verifica√ß√£o de membros em canais de voz conclu√≠da")
        
    except Exception as e:
        logger.error(f"Erro na verifica√ß√£o de canais de voz: {e}")

async def detect_missing_voice_leaves():
    """Detecta sess√µes que provavelmente foram encerradas durante uma queda"""
    await bot.wait_until_ready()
    
    if not hasattr(bot, 'db') or not bot.db or not bot.db._is_initialized:
        logger.error("Banco de dados n√£o inicializado - pulando detec√ß√£o de sess√µes perdidas")
        return
    
    try:
        logger.info("Iniciando detec√ß√£o de sess√µes de voz perdidas...")
        
        # Obter todas as sess√µes ativas do banco de dados
        async with bot.db.pool.acquire() as conn:
            active_sessions = await conn.fetch('''
                SELECT user_id, guild_id, last_voice_join 
                FROM user_activity 
                WHERE (last_voice_leave IS NULL OR last_voice_leave < last_voice_join)
                AND last_voice_join < NOW() - INTERVAL '10 minutes'
            ''')
            
        for session in active_sessions:
            guild = bot.get_guild(session['guild_id'])
            if not guild:
                continue
                
            member = guild.get_member(session['user_id'])
            if not member:
                continue
                
            # Verificar se o membro n√£o est√° mais em um canal de voz
            if not member.voice or not member.voice.channel:
                # Garantir que last_voice_join est√° com timezone
                join_time = session['last_voice_join']
                if join_time.tzinfo is None:
                    join_time = join_time.replace(tzinfo=pytz.UTC)
                
                # CORRE√á√ÉO: Remover o limite de 10 minutos e calcular a dura√ß√£o real.
                # A dura√ß√£o ser√° o tempo desde a entrada at√© agora (momento da reinicializa√ß√£o).
                duration = (datetime.now(pytz.UTC) - join_time).total_seconds()

                # Adicionar um limite razo√°vel para evitar sess√µes absurdamente longas se o bot
                # ficar offline por dias. Um limite de 24 horas √© uma salvaguarda segura.
                max_duration = timedelta(hours=24).total_seconds()
                duration = min(duration, max_duration)
                
                # Registrar sa√≠da no banco de dados
                try:
                    await bot.db.log_voice_leave(member.id, guild.id, int(duration))
                    
                    # Se t√≠nhamos uma sess√£o ativa, remover
                    audio_key = (member.id, guild.id)
                    if audio_key in bot.active_sessions:
                        del bot.active_sessions[audio_key]
                        
                    logger.info(f"Sess√£o que terminou durante a queda do bot foi encerrada para {member.display_name} com dura√ß√£o de {duration//60:.0f} minutos")
                    
                except Exception as e:
                    logger.error(f"Erro ao registrar sa√≠da estimada: {e}")
        
        logger.info("Detec√ß√£o de sess√µes de voz perdidas conclu√≠da")
    except Exception as e:
        logger.error(f"Erro na detec√ß√£o de sess√µes perdidas: {e}")

@log_task_metrics("cleanup_processed_events")
async def cleanup_processed_events():
    """Limpa eventos de voz j√° processados"""
    await bot.wait_until_ready()
    
    while True:
        try:
            if hasattr(bot, 'db') and bot.db and bot.db._is_initialized:
                async with bot.db.pool.acquire() as conn:
                    # Limpar eventos com mais de 7 dias
                    await conn.execute('''
                        DELETE FROM pending_voice_events
                        WHERE processed = TRUE
                        AND event_time < NOW() - INTERVAL '7 days'
                    ''')
            
            await asyncio.sleep(86400)  # Executar uma vez por dia
        except Exception as e:
            logger.error(f"Erro na limpeza de eventos processados: {e}")
            await asyncio.sleep(3600)  # Tentar novamente em 1 hora se falhar

@log_task_metrics("cleanup_ghost_sessions")
async def cleanup_ghost_sessions():
    """Limpa sess√µes fantasmas no banco de dados"""
    await bot.wait_until_ready()
    
    if not hasattr(bot, 'db') or not bot.db or not bot.db._is_initialized:
        logger.error("Banco de dados n√£o inicializado - pulando limpeza de sess√µes fantasmas")
        return
    
    try:
        logger.info("Iniciando limpeza de sess√µes fantasmas...")
        
        now = datetime.now(pytz.UTC)
        to_remove = []
        
        # Limpar sess√µes estimadas que excederam o tempo m√°ximo
        for key, session in bot.active_sessions.items():
            if session.get('estimated') and 'max_estimated_time' in session:
                if now > session['max_estimated_time']:
                    to_remove.append(key)
                    # Registrar sa√≠da no banco de dados
                    try:
                        duration = (session['max_estimated_time'] - session['start_time']).total_seconds()
                        await bot.db.log_voice_leave(key[0], key[1], int(duration))
                    except Exception as e:
                        logger.error(f"Erro ao registrar sa√≠da estimada: {e}")
        
        for key in to_remove:
            bot.active_sessions.pop(key, None)
            logger.info(f"Removida sess√£o estimada expirada para usu√°rio {key[0]} na guild {key[1]}")
        
        # Corrigir sess√µes onde last_voice_join > last_voice_leave h√° mais de 24 horas
        async with bot.db.pool.acquire() as conn:
            ghost_sessions = await conn.fetch('''
                UPDATE user_activity 
                SET last_voice_leave = COALESCE(last_voice_join, NOW()) + INTERVAL '1 hour',
                    total_voice_time = total_voice_time + 3600
                WHERE (last_voice_leave IS NULL OR last_voice_join > last_voice_leave)
                AND (last_voice_join < NOW() - INTERVAL '24 hours')
                RETURNING user_id, guild_id, last_voice_join
            ''')
            
            if ghost_sessions:
                logger.info(f"Limpeza conclu√≠da: {len(ghost_sessions)} sess√µes fantasmas corrigidas")
                
                # Registrar sess√µes de voz para os membros afetados
                for session in ghost_sessions:
                    try:
                        join_time = session['last_voice_join']
                        if join_time.tzinfo is None:
                            join_time = join_time.replace(tzinfo=pytz.UTC)
                            
                        await conn.execute('''
                            INSERT INTO voice_sessions
                            (user_id, guild_id, join_time, leave_time, duration)
                            VALUES ($1, $2, $3, $4, $5)
                        ''', 
                        session['user_id'], 
                        session['guild_id'],
                        join_time,
                        join_time + timedelta(hours=1),
                        3600)
                    except Exception as e:
                        logger.error(f"Erro ao registrar sess√£o fantasma: {e}")
                        continue
    except Exception as e:
        logger.error(f"Erro na limpeza de sess√µes fantasmas: {e}")

async def cleanup_ghost_sessions_wrapper():
    """Wrapper para a task de limpeza de sess√µes fantasmas"""
    monitoring_period = 1  # Executar diariamente
    task = bot.loop.create_task(execute_task_with_persistent_interval(
        "cleanup_ghost_sessions",
        monitoring_period,
        cleanup_ghost_sessions
    ), name='cleanup_ghost_sessions_wrapper')
    return task

@log_task_metrics("register_role_assignments")
async def register_role_assignments():
    """Registra datas de atribui√ß√£o de cargos para membros existentes"""
    await bot.wait_until_ready()
    
    # Verificar se o banco de dados est√° dispon√≠vel
    if not hasattr(bot, 'db') or not bot.db or not bot.db._is_initialized:
        logger.error("Banco de dados n√£o inicializado - pulando registro de atribui√ß√µes de cargos")
        return
    
    # Verificar se h√° cargos monitorados configurados
    if not bot.config.get('tracked_roles'):
        logger.info("Nenhum cargo monitorado definido - pulando registro de atribui√ß√µes")
        return
    
    try:
        for guild in bot.guilds:
            logger.info(f"Registrando atribui√ß√µes de cargos para guild {guild.name} (ID: {guild.id})")
            
            tracked_roles = bot.config['tracked_roles']
            
            # Processar em lotes menores para evitar sobrecarga
            batch_size = 20
            members = list(guild.members)
            
            for i in range(0, len(members), batch_size):
                batch = members[i:i + batch_size]
                
                # Verificar quais membros j√° t√™m registros de atribui√ß√£o
                try:
                    async with bot.db.pool.acquire() as conn:
                        existing_assignments = await conn.fetch('''
                            SELECT DISTINCT user_id FROM role_assignments
                            WHERE guild_id = $1 AND role_id = ANY($2)
                        ''', guild.id, tracked_roles)
                    
                    existing_user_ids = {r['user_id'] for r in existing_assignments}
                    
                    for member in batch:
                        try:
                            # Verificar se tem cargos monitorados e n√£o est√° registrado
                            if member.id not in existing_user_ids:
                                member_roles = [role for role in member.roles if role.id in tracked_roles]
                                
                                if member_roles:
                                    # Registrar data de atribui√ß√£o para cada cargo
                                    for role in member_roles:
                                        try:
                                            await bot.db.log_role_assignment(member.id, guild.id, role.id)
                                            logger.debug(f"Registrado cargo {role.name} para {member.display_name}")
                                        except Exception as e:
                                            logger.error(f"Erro ao registrar cargo {role.id} para {member}: {e}")
                                            continue
                                            
                        except Exception as e:
                            logger.error(f"Erro ao processar membro {member}: {e}")
                            continue
                
                except Exception as e:
                    logger.error("Erro ao verificar atribui√ß√µes existentes", exc_info=True)
                    continue
                
                # Pequeno delay entre lotes para evitar rate limits
                await asyncio.sleep(1)
                
    except Exception as e:
        logger.error(f"Erro na task register_role_assignments: {e}")

async def process_member_role_assignments(member: discord.Member, tracked_roles: List[int]):
    """Processa e registra as atribui√ß√µes de cargos para um √∫nico membro"""
    try:
        for role in member.roles:
            if role.id in tracked_roles:
                try:
                    # Verificar se j√° existe registro no banco de dados
                    assigned_time = None
                    try:
                        assigned_time = await bot.db.get_role_assigned_time(
                            member.id, member.guild.id, role.id)
                    except Exception as e:
                        logger.error(f"Erro ao verificar atribui√ß√£o de cargo {role.id} para {member.id}: {e}")
                        continue
                    
                    if not assigned_time:
                        # Registrar com a data atual
                        try:
                            await bot.db.log_role_assignment(
                                member.id, member.guild.id, role.id)
                            logger.debug(f"Registrado cargo {role.name} para {member.display_name}")
                        except Exception as e:
                            logger.error(f"Erro ao registrar atribui√ß√£o de cargo {role.id} para {member.id}: {e}")
                            continue
                except Exception as e:
                    logger.error(f"Erro ao processar cargo {role.id} para {member.display_name}: {e}")
                    continue
    except Exception as e:
        logger.error(f"Erro ao processar atribui√ß√µes de cargos para {member.display_name}: {e}")

async def register_role_assignments_wrapper():
    """Wrapper para a task com intervalo persistente"""
    monitoring_period = 1  # Executar diariamente
    task = bot.loop.create_task(execute_task_with_persistent_interval(
        "register_role_assignments",
        monitoring_period,
        register_role_assignments
    ), name='register_role_assignments_wrapper')
    return task

# --- NOVA TAREFA PARA LIMPEZA DE MENSAGENS ANTIGAS ---
@log_task_metrics("cleanup_old_bot_messages")
async def _cleanup_old_bot_messages():
    """Verifica os canais de log e notifica√ß√£o e apaga mensagens do bot mais antigas que 7 dias."""
    await bot.wait_until_ready()

    # Pega os IDs dos canais a partir da configura√ß√£o do bot
    log_channel_id = bot.config.get('log_channel')
    notification_channel_id = bot.config.get('notification_channel')
    
    channels_to_clean = []
    if log_channel_id:
        channels_to_clean.append(log_channel_id)
    if notification_channel_id:
        channels_to_clean.append(notification_channel_id)

    if not channels_to_clean:
        logger.info("Nenhum canal de log ou notifica√ß√£o configurado para limpeza de mensagens.")
        return

    # Define o ponto de corte: qualquer mensagem antes desta data ser√° apagada
    cutoff_date = datetime.now(pytz.utc) - timedelta(days=7)
    
    deleted_count_total = 0

    for channel_id in channels_to_clean:
        try:
            channel = bot.get_channel(channel_id)
            if not channel or not isinstance(channel, discord.TextChannel):
                logger.warning(f"N√£o foi poss√≠vel encontrar o canal de texto com ID {channel_id} para limpeza.")
                continue

            # A fun√ß√£o purge √© muito eficiente para apagar m√∫ltiplas mensagens
            # Ela apaga mensagens que s√£o ANTERIORES √† data de corte (`before`)
            # e que passam na verifica√ß√£o (`check`), que no nosso caso √© se o autor √© o pr√≥prio bot.
            deleted_messages = await channel.purge(
                limit=None,  # Sem limite, apaga todas que corresponderem
                before=cutoff_date,
                check=lambda m: m.author == bot.user
            )
            
            if deleted_messages:
                count = len(deleted_messages)
                deleted_count_total += count
                logger.info(f"Limpeza conclu√≠da para o canal #{channel.name}: {count} mensagens antigas do bot foram apagadas.")

        except discord.Forbidden:
            logger.error(f"N√£o tenho permiss√£o para apagar mensagens no canal com ID {channel_id}.")
        except Exception as e:
            logger.error(f"Ocorreu um erro ao limpar mensagens no canal ID {channel_id}: {e}", exc_info=True)
        
        # Adiciona um pequeno delay para n√£o sobrecarregar a API do Discord
        await asyncio.sleep(5)

    if deleted_count_total > 0:
        logger.info(f"Limpeza peri√≥dica de mensagens conclu√≠da. Total de {deleted_count_total} mensagens apagadas.")

async def cleanup_old_bot_messages():
    """Wrapper para a task de limpeza de mensagens com intervalo de 6 horas."""
    # A l√≥gica de intervalo persistente n√£o √© necess√°ria aqui, pois a tarefa √© de limpeza
    # e pode rodar a cada X horas sem problemas, mesmo que atrase um pouco.
    @tasks.loop(hours=6)
    async def loop():
        await _cleanup_old_bot_messages()

    # Adiciona um before_loop para garantir que a task s√≥ comece quando o bot estiver pronto
    @loop.before_loop
    async def before_cleanup_loop():
        await bot.wait_until_ready()

    # Inicia a task
    loop.start()